<!-- -*- fill-column: 100; -*- -->
<!DOCTYPE HTML>
<!-- Based on Read Only by HTML5 UP, html5up.net | @n33co (html5up.net/license) -->
<html lang="en">

  <head>
    <title>Things and stuff</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if lte IE 8]>
        <script src="assets/js/ie/html5shiv.js"></script>
        <![endif]-->
    <link rel="stylesheet" href="assets/css/everything.min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="assets/css/ie8.min.css">
        <![endif]-->
    <!-- Use fontello-generated webfont with IE < 7 -->
    <!--[if lte IE 7]>
        <link rel="stylesheet" href="assets/css/fa-mini-ie7.min.css">
        <![endif]-->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-74190850-2"></script>
    <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'UA-74190850-2');
    </script>
  </head>
  
  <body>
    <!-- Header -->
    <section id="header">
      <nav id="nav">
        <ul>
          <li><a href="#one" class="active">This site</a></li>
          <li><a href="#math">Mathematics</a></li>
          <li><a href="#ml">Machine Learning</a></li>
          <li><a href="#software">Software</a></li>
          <li><a href="#teaching">Teaching</a></li>
          <li><a href="#people">People</a></li>
          <li><a href="#about">About &amp; Contact</a></li>
        </ul>
      </nav>
      <footer>
        <ul class="icons">
          <li><a href="https://bitbucket.org/mdbenito/" class="icon-bitbucket"
                 title="Repositories in Bitbucket" rel="tipsy"></a></li>
          <li><a href="https://github.com/mdbenito/" class="icon-github-circled"
                 title="Repositories in GitHub" rel="tipsy"></a></li>
          <li><a href="#about" class="icon-mail-alt" title="Drop me a line"
                 rel="tipsy"></a></li>
          <li><a href="https://stackexchange.com/users/230074/miguel?tab=accounts"
                 class="icon-stackexchange" title="Stack Exchange" rel="tipsy"></a></li>
          <li><a href="https://appliedai.de/"
                 class="icon-bank" title="Work" rel="tipsy"></a></li>
        </ul>
      </footer>
    </section>
    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Main -->
      <div id="main">
        <!-- One -->
        <section id="one">
          <div class="container">
            <header>
              <h2 class="title" id="logo" style="display:none;">Things and stuff</h2>

              <p><a class="-link" href="#about">I</a> am a person. I do things and stuff.
                Mostly <a class="-link" href="#math">math</a>, often <a class="-link"
                href="#software">software</a>, usually with <a class="-link"
                href="#people">people</a>. This site collects some personal projects, mathematical
                and otherwise.</p>
              <p>Some of these projects were not originally intended or are not yet ready
                for public release. Accordingly, some links are disabled. Don't hesitate
                to <a class="-link" href="#about">contact me</a> if you are interested in any of them.</p>
            </header>
            <ul class="icons">
              <li><a class="icon-down-big -link" href="#math"></a>
              </li>
            </ul>
          </div>
        </section>
        <!-- Math -->
        <section id="math">
          <div class="container">
            <header class="major">
              <h3>Mathematics</h3>
            </header>
            <div class="features">
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/hierarchy.png"><noscript><img src="images/math/hierarchy.png" alt="A hierarchy of plate models"></noscript>
                  <span class="vertical-label">Mar 2021</span>
                </span>
                <div class="inner">
                    <h4>A hierarchy of multilayered plate models (ESAIM: COCV)</h4>

                  <p>We derive a hierarchy of plate theories for heterogeneous multilayers
                  from three dimensional nonlinear elasticity by means of Γ-convergence. 
                  We allow for layers composed of different materials whose constitutive 
                  assumptions may vary significantly in the small film direction and which 
                  also may have a (small) pre-stress. By computing the Γ-limits in the 
                  energy regimes in which the scaling of the pre-stress is non-trivial, 
                  we arrive at linearised Kirchhoff, von Kármán, and fully linear plate 
                  theories, respectively, which contain an additional spontaneous curvature 
                  tensor. The effective (homogenised) elastic constants of the plates will 
                  turn out to be given in terms of the moments of the pointwise elastic 
                  constants of the materials.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="files/math/debenito_schmidt_hierarchy_2021.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-doc-text" href="https://doi.org/10.1051/cocv/2020067"
                         title="Publisher's site" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#bernd"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/effective.jpg"><noscript><img src="images/math/effective.jpg" alt="Changes in shape and critical parameter"></noscript>
                  <span class="vertical-label">Mar 2020</span>
                </span>
                <div class="inner">
                  <h4>Energy Minimising Configurations of Pre-strained Multilayers (J. Elast.)</h4>

                  <p>We investigate energetically optimal configurations of thin structures with a
                    pre-strain. Depending on the strength of the pre-strain we consider a whole
                    hierarchy of effective plate theories with a spontaneous curvature term, ranging
                    from linearised Kirchhoff to von Kármán to linearised von Kármán theories. While
                    explicit formulae are available in the linearised regimes, the von Kármán theory
                    turns out to be critical and a phase transition from cylindrical (as in linearised Kirchhoff)
                    to spherical or saddle-shaped (as in linearised von Kármán) configurations is
                    observed there. We analyse this behaviour with the help of a whole family
                    ($I^{θ})_{θ∈(0,∞)}$ of effective von Kármán functionals which interpolates between
                    the two linearised regimes. We rigorously show convergence to the respective
                    explicit minimisers in the asymptotic regimes $θ → 0$ and $θ → ∞$. Numerical
                    experiments are performed for general $θ∈(0,∞)$ which indicate a stark transition
                    in a critical region of parameters θ.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="files/math/debenito_schmidt_energy_2020.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-doc-text" href="https://doi.org/10.1007/s10659-020-09771-y"
                         title="Publisher's site" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#bernd"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/phd-thesis-cover.jpg"><noscript><img src="images/math/phd-thesis-cover.jpg" alt="Book cover"></noscript>
                  <span class="vertical-label">2014 - 2019</span>
                </span>
                <div class="inner">
                  <h4>Effective theories for multilayered plates (Ph.D. thesis)</h4>

                  <p>We derive by $Γ$-convergence a family of effective plate theories for
                    multilayered materials with internal misfit for scaling laws ranging from
                    Kirchhoff's theory to linearised von Kármán. The main addition is the central
                    role played by an intermediate von Kármán-like theory, where a new parameter
                    interpolates between the adjacent regimes. We also prove the $Γ$-convergence of
                    this limiting regime to the other two as well as the relevant compactness
                    results and we characterise some minimising configurations for the scalings
                    considered. Finally, we numerically investigate the interpolating regime
                    employing the open source toolkit
                    <a href="https://fenicsproject.org/">FEniCS</a> to implement a discrete gradient
                    flow. This provides empirical evidence for the existence of a critical value of
                    the parameter around which minimisers are of different nature. We show
                    $Γ$-convergence of the discretisation and compactness as the mesh size goes to
                    zero.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="files/math/debenito_effective_2019.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/lvk"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="files/math/phd-talk.pdf"
                         title="Slides 2019" rel="tipsy"></a></li>
                  <li><a class="icon-doc-text" href="https://doi.org/10.30819/4984"
                         title="Publisher's site" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#bernd"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/signorini.svg"><noscript><img src="images/math/signorini.svg"></noscript>
                  <span class="vertical-label">Nov 2018</span>
                </span>
                <div class="inner">
                  <h4>Some remarks on the contact set for the Signorini problem (Opusc. Math.)</h4>

		  <p>We study some properties of the coincidence set for the <em>boundary Signorini
		  problem</em>, improving previous work in the literature. Among other new results,
                  we show here that the convexity assumption on the domain made previously in the
                  literature on the location of the coincidence set can be avoided under suitable
                  alternative conditions on the data.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="files/math/debenito_diaz_remarks_2019.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-laptop disabled" href="files/math/some-remarks-signorini-talk.pdf"
                         title="Slides 2014" rel="tipsy"></a></li>
                  <li><a class="icon-doc-text" href="https://doi.org/10.7494/OpMath.2019.39.2.145"
                         title="Publisher's site" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#ildefonso"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/ma.png">
                  <noscript><img src="images/math/ma.png"></noscript>
                  <span class="vertical-label">Mar 2013</span>
                </span>
                <div class="inner">
                  <h4>On the contact between two linearly elastic bodies (Master's thesis)</h4>

                  <p>We first introduce the problem of the contact of two elastic bodies in
                    the context of classical linear elasticity, then gather all necessary results
                    for the proof of existence and uniqueness of a solution. The main proof
                    of existence is conducted using two different approaches, depending on
                    the coercivity of the bilinear form associated with the elastic potential.
                    We briefly present a finite element discretization and an algorithm for
                    the solution. In particular we focus on some fairly recent advances in
                    the resolution of the non-linearity at the contact zone via iterative methods
                    using a mortar method with dual Lagrange multipliers.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/signorini-dune"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf disabled" href="files/math/ma.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-laptop disabled" href="files/math/ma-tum-talk.pdf"
                         title="Slides 2013" rel="tipsy"></a></li>
                  <li><a class="icon-laptop disabled" href="files/math/ma-una-talk.pdf"
                         title="Slides 2014" rel="tipsy"></a></li>
                  <!-- <li><a class="icon-doc-text" href="files/math/ma.tm" title="TeXmacs source" rel="tipsy"></a></li> -->
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/math/ba.svg">
                  <noscript><img src="images/math/ba.svg"></noscript>
                  <span class="vertical-label">Jul 2012</span>
                </span>
                <div class="inner">
                  <h4>On a contact problem in elasticity (Bachelor's thesis)</h4>

                  <p>After a quick review of linear elasticity theory, we study the classical
                    problem which considers the stationary equilibrium of an elastic body resting
                    on a frictionless surface (Signorini problem). Its essential property is
                    found in the unilateral boundary conditions given in subsets of the boundary
                    unknown a priori which model the lack of knowledge about the region where
                    contact happens and make the problem non-linear. The coincidence set, where
                    the inequalities defining the boundary conditions become equalities, is
                    then studied in both the vectorial and the scalar settings from two viewpoints.
                    (...)</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="files/math/ba.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="files/math/ba-ucm-talk.pdf"
                         title="Slides 2012" rel="tipsy"></a></li>
                  <!-- <li><a class="icon-doc-text" href="files/math/ba.tm" title="TeXmacs source" rel="tipsy"></a></li> -->
                  <li><a class="icon-users people-link" href="#people" data-people="#ildefonso"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
            </div>
          </div>
        </section>
        <!-- Machine learning -->
        <section id="ml">
          <div class="container">
            <header>
              <h3>Statistics and machine learning</h3>
              <p>From the let-the-machine-tell-me dept.</p>
            </header>
            <p>I devote much of my time to statistical learning theory and machine learning.  I
              often write toy implementations or documents summarizing ideas or collecting proofs,
              sometimes by applications to real datasets.  The selection of topics is rather
              arbitrary, as is the depth with which they are covered, although they are mostly
              elementary. I usually try to keep some moderate level of rigour, but remain at the
              level of a practitioner of mild mathematical sophistication.</p>
            <div class="features">
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/cw-calibration.svg">
                  <noscript><img src="images/ml/cw-calibration.svg"></noscript>
                  <span class="vertical-label">Dec 2022</span>
                </span>
                <div class="inner">
                  <h4>Class-wise and reduced calibration (ICMLA 2022)</h4>
                  <p>For many applications of probabilistic classifiers it is important that the
                      predicted confidence vectors reflect true probabilities (one says that the
                      classifier is calibrated). It has been shown that common models fail to satisfy
                      this property, making reliable methods for measuring and improving calibration
                      important tools. Unfortunately, obtaining these is far from trivial for problems
                      with many classes. We propose two techniques that can be used in tandem. First,
                      a reduced calibration method transforms the original problem into a simpler
                      one. We prove for several notions of calibration that solving the reduced
                      problem minimizes the corresponding notion of miscalibration in the full
                      problem, allowing the use of non-parametric recalibration methods that fail in
                      higher dimensions. Second, we propose class-wise calibration methods, based on
                      intuition building on a phenomenon called neural collapse and the observation
                      that most of the accurate classifiers found in practice can be thought of as a
                      union of K different functions which can be recalibrated separately, one for
                      each class. These typically out-perform their non class-wise counterparts,
                      especially for classifiers trained on imbalanced data sets. Applying the two
                      methods together results in class-wise reduced calibration algorithms, which are
                      powerful tools for reducing the prediction and per-class calibration errors. We
                      demonstrate our methods on real and synthetic datasets and release all code as
                      open source <a href="https://github.com/appliedAI-Initiative">here</a>.
                  </p>
                  <p>This is joint work with my great colleagues
                      <a href="#people" class="people-link" data-people="#anes">Anes Benmerzoug</a>
                      and <a href="#people" class="people-link" data-people="#mischa">Michael Panchenko</a>,
                      appearing at the <a href="https://www.icmla-conference.org/icmla22">21st International
                      Conference on Machine Learning and Applications</a> (ICMLA 2022).
                  </p>
                </div>
                <ul class="icons">
                    <li><a class="icon-bitbucket" href="https://github.com/appliedAI-Initiative/classwise-calibration-experiments"
                           title="Code" rel="tipsy"></a></li>
                    <li><a class="icon-bitbucket" href="https://github.com/appliedAI-Initiative/kyle"
                           title="Code" rel="tipsy"></a></li>
                    <li><a class="icon-file-pdf" href="http://arxiv.org/abs/2210.03702"
                           title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#anes,#mischa"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/sisyphus.svg">
                  <noscript><img src="images/ml/sisyphus.svg"></noscript>
                  <span class="vertical-label">2017 - 2018</span>
                </span>
                <div class="inner">
                  <h4>PaperWhy</h4>
                  <p><a href="https://paperwhy.8027.org">PaperWhy</a> was my attempt to contribute to
                  the sisyphean endeavour not to drown in the immense Machine Learning literature. With
                  thousands of papers every month, keeping up with and making sense of recent
                  research has become almost impossible. By routinely reviewing and reporting about
                  papers I helped myself and hopefully someone else.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/paperwhy"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="https://paperwhy.8027.org"
                         title="Site" rel="tipsy"></a></li>
                </ul>
              </article>                
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/bml.png">
                  <noscript><img src="images/ml/bml.png"></noscript>
                  <span class="vertical-label">Jan 2015</span>
                </span>
                <div class="inner">
                  <h4>Bayesian model selection</h4>

                  <p>In this note we introduce <strong>linear regression with basis
                    functions</strong> in order to apply <strong>Bayesian model
                    selection</strong>. The goal is to incorporate Occam's razor through Bayesian
                    analysis in order to automatically pick the model optimally able to explain the
                    data without overfitting. This is joint fun with <a href="#people"
                    class="people-link" data-people="#philipp">Philipp Wacker</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/modelselection"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf" href="http://arxiv.org/abs/1512.04823"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="https://bitbucket.org/mdbenito/modelselection/raw/master/doc/Slides.pdf"
                         title="Slides" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#philipp"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/mcts.png">
                  <noscript><img src="images/ml/mcts.png"></noscript>
                  <span class="vertical-label">Feb 2016</span>
                </span>
                <div class="inner">
                  <h4>Monte Carlo Tree Search</h4>

                  <p><strong>MCTS</strong> is a moderately recent (2006) algorithm for playing games
                    by partially building their decision trees. The key is to use random simulations
                    of the game for those choices which seem most fruitful according to a criterion
                    balancing <em>exploration</em> of new venues and <em>exploitation</em> of good
                    ones. An implementation in Python for a simple game
                    of <strong><a href="https://en.wikipedia.org/wiki/Quantum_tic-tac-toe">Quantum
                    TicTacToe</a></strong> provides a nice testbed. This is joint fun with
                    <a href="#people" class="people-link" data-people="#ana">Ana Cañizares</a>,
                    based on work by
                    <a href="#people" class="people-link" data-people="#philipp">Philipp Wacker</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/quantum-tictactoe"
                         title="Code" rel="tipsy"></a></li>
                  <!-- <li><a class="icon-file-pdf" href="files/ml/mcts.pdf" title="Document" rel="tipsy"></a></li> -->
                  <li><a class="icon-users people-link" href="#people" data-people="#ana,#philipp"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image"><img class="lazy" data-src="images/ml/knn.png">
                  <noscript><img src="images/ml/knn.png" alt="Results window"></noscript>
                  <span class="vertical-label">Apr 2015</span>
                </span>
                <div class="inner">
                  <h4>K - nearest neighbours</h4>

                  <p><strong>KNN</strong> is one of the simplest non-parametric classification
                    algorithms. In this note, we start from basic ideas in <strong>kernel density
                    estimation</strong> and using Bayes' rule we derive this simple (albeit slow and
                    sloppy) algorithm which "only" requires the computation and sorting of distances
                    in $L^p$.  We test its performance on
                    the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> dataset
                    with a C++11 implementation
                    using <a href="http://arma.sourceforge.net/">Armadillo</a> and a viewer written
                    with <a href="https://www.qt.io/">Qt</a> for the results.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="https://bitbucket.org/mdbenito/knn" title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf disabled" href="https://bitbucket.org/mdbenito/knn/raw/master/doc/kde-knn.pdf" title="Document" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/km2em.svg">
                  <noscript><img src="images/ml/km2em.svg"></noscript>
                  <span class="vertical-label">Oct 2014</span>
                </span>
                <div class="inner">
                  <h4>K-means and Gaussian Mixtures</h4>

                  <p><strong>K-means</strong> is a simple clustering algorithm which matches each
                    data point to exactly one of $K$ clusters in a way such that the sum of the
                    squares of the distances of each data point to the center of mass of its
                    assigned cluster is minimal. We review how this minimization can be performed
                    iteratively in a manner closely linked to
                    <a class="-link" href="#em">Expectation Maximization</a> for <strong>Gaussian
                    mixtures</strong>. We also briefly discuss <strong>K-Means++</strong>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/km2em"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf" href="https://bitbucket.org/mdbenito/km2em/raw/master/doc/km2em.pdf"
                         title="Document" rel="tipsy"></a></li>
                </ul>
              </article>
              <article id="em">
                <span class="image">
                  <img class="lazy" data-src="images/ml/em.svg">
                  <noscript><img src="images/ml/em.svg"></noscript>
                  <span class="vertical-label">Oct 2014</span>
                </span>
                <div class="inner">
                  <h4>Expectation maximization</h4>

                  <p><strong>EM</strong> is a generic iterative algorithm for the maximization of the log
                    likelihood. Following (very closely) Bishop's classical book we discuss its
                    general form, applied to <strong>Gaussian models</strong> with latent variables as
                    motivation. Some limitations are discussed. Finally we also say a few words
                    about the <strong>Kullback-Leibler</strong> divergence and other information theoretic
                    ideas to show why EM works.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-file-pdf" href="https://bitbucket.org/mdbenito/km2em/raw/master/doc/em.pdf"
                         title="Document" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/svm.png">
                  <noscript><img src="images/ml/svm.png"></noscript>
                  <span class="vertical-label">May 2015</span>
                </span>
                <div class="inner">
                  <h4>Support Vector Machines</h4>

                  <p>Starting with some elementary ideas on how to tackle the task of assigning
                    labels to images, we progress onto the classical <strong>Perceptron</strong>,
                    then introduce <strong>Optimal Margin Classifiers</strong> and finally the
                    primal version of the <strong>SVM</strong>. From there we do a short detour
                    through <strong>dual Lagrange</strong> methods and introduce the standard dual
                    formulation of the SVM and the construction of higher dimensional feature spaces
                    with the <strong>kernel trick</strong>. Along the way we discuss optimisation
                    methods which enable us to use SVMs on large data sets. We provide an
                    implementation written in C++11, using
                    <a href="http://arma.sourceforge.net/">Armadillo</a>
                    and <a href="https://www.qt.io/">Qt</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="https://bitbucket.org/mdbenito/svm"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf" href="files/ml/svm-primer.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="files/ml/svm-slides.pdf"
                         title="Slides" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/data-assimilation.svg">
                  <noscript><img src="images/ml/data-assimilation.svg"></noscript>
                  <span class="vertical-label">Dec 2015</span>
                </span>
                <div class="inner">
                  <h4>Data assimilation</h4>

                  <p><strong>DA</strong> is the task of incorporating data into models given by
                    stochastic dynamical systems. In the simpler discrete case, one considers
                    stochastic dynamics given by $v_{j + 1} = Ψ (v_j) + ξ_j,$ with i.i.d additive
                    noise, together with a sequence of observations given by $y_{j + 1} = h(v_{j +
                    1}) + η_{j + 1}$, where $η_j$ is again i.i.d. These are Python implementations
                    of a few algorithms and examples from Law &amp; Stuart's book
                    <a href="http://www.springer.com/us/book/9783319203249">Data Assimilation</a>,
                    partly written in collaboration with
                    <a href="#people" class="people-link" data-people="#philipp">Philipp Wacker</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/data-assimilation"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#philipp"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/hmm.svg" alt="Hidden Markov Models">
                  <noscript><img src="images/ml/hmm.svg" alt="Hidden Markov Models"></noscript>
                  <span class="vertical-label">Dec 2015</span>
                </span>
                <div class="inner">
                  <h4>Hidden Markov Models</h4>

                  <p>A (pure, vectorized) Python implementation of an <strong>HMM</strong> with
                    discrete emissions given either by probability tables or Poisson distributions.
                    Parameter estimation is done using the <strong>Baum-Welch</strong> algorithm for
                    HMMs, which actually is <strong>Expectation Maximization</strong>. In this
                    application we experience how badly EM tends to get stuck in local optima. This
                    code was written during a short stay at the chair of Computational Neuroscience
                    in the <a href="http://www.neuro.bio.lmu.de/">department of Neurobiology</a> of
                    the Ludwig-Maximilians-Universität München.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/hmm"
                         title="Code" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/ars.svg">
                  <noscript><img src="images/ml/ars.svg"></noscript>
                  <span class="vertical-label">Feb 2016</span>
                </span>
                <div class="inner">
                  <h4>Adaptive Rejection Sampling</h4>

                  <p><strong>ARS</strong> is a general technique for sampling from a
                    <a href="https://en.wikipedia.org/wiki/Logarithmically_concave_function">log-concave</a>
                    distribution.  An upper bound of the target density is computed using tangents
                    to its logarithm, then transformed back into a sum of exponentials from which it
                    is easy to sample. After explaining the algorithm we provide basic theoretical
                    justification for it. In a simple Python implementation we also test
                    <a href="https://github.com/HIPS/autograd">autograd</a>, a package for
                    <strong><a href="https://en.wikipedia.org/wiki/Automatic_differentiation">Automatic Differentiation</a></strong>.
                    Work with <a href="#people" class="people-link" data-people="#alvaro">Álvaro Tejero</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="https://bitbucket.org/mdbenito/sampling"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-file-pdf disabled" href="https://bitbucket.org/mdbenito/sampling/raw/master/doc/ars.pdf"
                         title="Document" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#alvaro"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/ml/cmusml.svg">
                  <noscript><img src="images/ml/cmusml.svg"></noscript>
                  <span class="vertical-label">Apr 2016</span>
                </span>
                <div class="inner">
                  <h4>SML @ CMU</h4>

                  <p>Python + <strong>C</strong>ython implementation of some algorithms from Larry
                    Wasserman's course <a href="http://www.stat.cmu.edu/~larry/=sml/">"Statistical
                    Machine Learning"</a> at Carnegie Mellon University. For now, I only have
                    nonparametric regression, with <strong>Nadaraya-Watson</strong>, <strong>Local
                    Polynomial Regression</strong> and <strong>Generalized</strong>
                    or <strong>Leave-One-Out cross-validation</strong> applied to select the
                    bandwidth. For the multidimensional case I implemented
                    standard <strong>Backfitting</strong> for <strong>Additive Models</strong>
                    and <strong>SpAM</strong> (Sparse Additive Models) for the high dimensional
                    case.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="https://bitbucket.org/mdbenito/cmusml"
                         title="Code" rel="tipsy"></a></li>
                </ul>
              </article>
            </div>
          </div>
        </section>
        <!-- Software -->
        <section id="software">
          <div class="container">
            <header>
              <h2>Software</h2>
              <p>From the code-monkey dept.</p>
            </header>
            <div class="features">
              <article>
                <div class="image"><a href="http://www.texmacs.org"><img class="lazy" data-src="images/misc/texmacs.svg" style="padding:0 25% 1em 25%;"><noscript><img src="images/misc/texmacs.svg" style="padding:0 25% 1em 25%;" alt="TeXmacs icon" ></noscript></a>
                  <span class="vertical-label">2011 - 2015</span>
                  <h4>TeXmacs</h4>
                  <p><a href="http://www.texmacs.org"> TeXmacs</a> is an open source, fully fledged
                    scientific editor, mostly developed
                    by <a href="http://www.texmacs.org/joris/main/joris.html"> Joris van der
                    Hoeven</a> with the help
                    of <a href="http://texmacs.org/tmweb/contribute/team.en.html">a few core
                    developers</a> and
                    <a href="http://texmacs.org/tmweb/about/authors.en.html">a myriad contributors</a>. Most
                    of <a href="https://www.openhub.net/p/texmacs/contributors/18588618610071">my work</a> took
                    place between 2011 and 2015. There is a complete list of my subprojects in
                    <a href="http://texmacs.org/tmweb/contribute/team-miguel.en.html">my page at texmacs.org</a>.
                    Sadly, as my PhD advanced, my involvement with TeXmacs had to decline.</p>
                </div>
                <div class="inner" style="vertical-align:top;">
                  <p>Despite its name TeXmacs isn't either a plugin
                    for <a href="https://www.gnu.org/software/emacs/">Emacs</a> nor a frontend
                    to <a href="https://en.wikipedia.org/wiki/TeX">TeX</a>. It defines a document
                    format, features a macro language for extensions, innumerable plugins with
                    embedded sessions, a vector graphics tool, scientific spreadsheets, bibliography
                    management, remote sessions and a long, long list of features.  On top of all
                    that TeXmacs provides god-like powers over your documents thanks
                    to <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>.
                    Try it and never look back!</p>
                  <p style="text-align:center">
                    <!--
                    <script type="text/javascript"
                         src="https://www.openhub.net/p/texmacs/widgets/project_languages?format=js"></script>
                       -->
                      <iframe src='https://www.openhub.net/p/texmacs/widgets/project_languages'
                              scrolling='no' marginHeight='0' marginWidth='0'
                              style='height: 210px; width: 350px; border: none'></iframe>
                  </p>
                  <!-- <p>I've sometimes documented the process of developing new features for
                  TeXmacs using a TeXmacs document: a poor-man's literate programming of sorts. I've
                  formatted some of these drafts into rough tutorials with the idea that they might
                  help the newcomer. You can find them ...</p> -->
                </div>
                <ul class="icons" style="text-align:center;">
                  <li><a class="icon-file-pdf" href="files/tm/lit2015-talk.pdf"
                         title="Talk at the 14. Augsburger Linux Infotag (2015)" rel="tipsy"></a></li>
                  <li><a class="icon-laptop" href="files/tm/lit2015-talk-everything.zip"
                         title="Source files for the talk at the 14. Augsburger Linux Infotag (2015)" rel="tipsy"></a></li>
                  <li><a class="icon-mail-alt" href="mailto:mdbenito@SOFTWARE'SNAME.org"
                         title="Use this address if you have some project or idea you need help with" rel="tipsy"></a></li>
                  <li><a class="icon-users" href="http://texmacs.org/tmweb/contribute/team.en.html"
                         title="The TeXmacs team" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/misc/puzzle.jpg">
                  <noscript><img src="images/misc/puzzle.jpg" alt="Screenshot of PzzApp"></noscript>
                  <span class="vertical-label">Apr 2012</span>
                </span>
                <div class="inner">
                  <h4>PzzApp</h4>

                  <p>A simple 15-puzzle game written in Cocoa with
                    <a href="#people" class="people-link" data-people="#ana">Ana Cañizares</a>.
                    This is our first and only application in this language, mostly written during
                    an intense weekend-hackathon.  Don't raise your expectations too high.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/pzzapp"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#ana"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/misc/rubiq.jpg">
                  <noscript><img src="images/misc/rubiq.jpg" alt="Screenshot of rubiQ"></noscript>
                  <span class="vertical-label">Jul 2007</span>
                </span>
                <div class="inner">
                  <h4>rubiQ</h4>

                  <p>An OpenGL interface for a Rubik's cube solver. I wrote this after my first
                    algebra course, where we used semi-direct products to model the group of
                    transformations of the cube. The solver used brute-force to compute the
                    movements graph for the last layer of the cube, assuming the first two have been
                    completed. Written in C++ and Qt.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="" style="color:grey;"
                         title="Code" rel="tipsy"></a></li>
                </ul>
              </article>
              <article>
                <span class="image">
                  <img class="lazy" data-src="images/misc/clong.svg">
                  <noscript><img src="images/misc/clong.svg" alt="Clong! logo"></noscript>
                  <span class="vertical-label">Oct 2015</span>
                </span>
                <div class="inner">
                  <h4>Clong!</h4>

                  <p>A clone of the 1972 classic Pong written
                    in <a href="https://clojure.org/">clojure</a> with the idea of having fun and
                    learning clojure while coding it. We use a naive implementation of
                    the <a href="https://en.wikipedia.org/wiki/Entity_component_system">Entity-Component-System
                    framework</a>, closely following Chris Granger's blog
                    post <a href="http://www.chris-granger.com/2012/12/11/anatomy-of-a-knockout">Anatomy
                    of a Knockout</a>.</p>
                </div>
                <ul class="icons">
                  <li><a class="icon-bitbucket disabled" href="https://bitbucket.org/mdbenito/clong"
                         title="Code" rel="tipsy"></a></li>
                  <li><a class="icon-users people-link" href="#people" data-people="#ana"
                         title="People" rel="tipsy"></a></li>
                </ul>
              </article>
            </div>
          </div>
        </section>
        <!-- Teaching -->
        <section id="teaching">
          <div class="container">
            <header>
              <h2>Teaching</h2>

              <p>From the nobody-cares dept.</p>
            </header>
            <ul class="simple-list">
              <li>WS 2015: Übung Dynamische Systeme (UNA, <a href="https://www.math.uni-augsburg.de/prof/ana/arbeitsgruppe/bloemker/">Prof. Dr. Dirk Blömker</a>).
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/15WS-DS-Aufgaben.pdf"></a>
              </li>
              <li>WS 2015: Tutorübung Brückenkurs Mathematik (UNA).</li>
              <li>SS 2015: Tutorübung Gewöhnliche Differentialgleichungen (UNA, <a href="">Dr. Evgeny Volkov</a>).
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/15SS-GDG-Aufgaben.pdf"></a>
              </li>
              <li>WS 2014: Assistent Analysis 3 (UNA,
                <a class="people-link" href="#people" data-people="#bernd">Prof. Dr. Bernd Schmidt</a>).
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/14WS-A3-Aufgaben.pdf"></a>
              </li>
              <li>SS 2014: Tutorübung Analysis 2 (UNA,
                <a class="people-link" href="#people" data-people="#bernd">Prof. Dr. Bernd Schmidt)</a>.
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/14SS-A2-Aufgaben.pdf"></a>
              </li>
              <li>WS 2013: Tutorübung Höhere Mathematik 1 für Bau-, Umweltingenieurwesen
                und Geodäsie (TUM, <a href="http://www-m8.ma.tum.de/personen/scheurle/">Prof. Dr. Jürgen Scheurle</a>).
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/13WS-HM1-Aufgaben.pdf"></a>
              </li>
              <li>SS 2013: Tutorübung Höhere Mathematik 2 für Bau-, Umweltingenieurwesen
                und Geodäsie (TUM, <a href="http://www-m8.ma.tum.de/personen/scheurle/">Prof. Dr. Jürgen Scheurle</a>).
                <a class="icon-file-pdf" style="float:right;" href="files/teaching/13SS-HM2-Aufgaben.pdf"></a>
              </li>
            </ul>
          </div>
        </section>
        <!-- People -->
        <section id="people" data-people="#luigi,#ana,#ildefonso,#bernd,#alvaro,#philipp">
          <div class="container">
            <header>
              <h2>People</h2>

            </header>
            <p>It is a trite thing to say but still true: I owe so much to so many people
              that it would be impossible to list them all. These are those directly
              involved in the projects above.</p>
            <ul class="feature-icons">
                <!-- <li id="luigi"><a href="https://www.math.uni-augsburg.de/prof/ana/arbeitsgruppe/bianchi/">Luigi Amedeo Bianchi</a></li> -->
                <li id="anes"><a href="https://anesbenmerzoug.github.io/">Anes Benmerzoug</a></li>
                <li id="ana"><a href="http://www.mathematik.uni-muenchen.de/~caniz/">Ana Cañizares García</a></li>
                <li id="ildefonso"><a href="http://www.mat.ucm.es/~jidiaz/">Jesús Ildefonso Díaz Díaz</a></li>
                <li id="mischa"><a href="https://github.com/MischaPanch">Michael Panchenko</a></li>
                <li id="bernd"><a href="https://www.uni-augsburg.de/de/fakultaet/mntf/math/prof/ana/prof-dr-bernd-schmidt/">Bernd Schmidt</a></li>
              <li id="alvaro"><a href="https://scholar.google.com/citations?user=VObPwpUAAAAJ&hl=en">Álvaro Tejero Cantero</a></li>
              <li id="philipp"><a href="https://scholar.google.com/citations?user=q2YWR1IAAAAJ&hl=en">Philipp Wacker</a></li>
              <li id="me"><a href="#about">Miguel de Benito Delgado</a></li>
              <li></li><!-- needed -->
            </ul>
          </div>
        </section>
        <!-- About & Contact -->
        <section id="about">
          <div class="container">
            <header>
              <h3>About me</h3>
              <p>From the self-plug dept.</p>
            </header>
            <p>
              <span class="image right">
                <img class="lazy image avatar" data-src="images/people/me.svg">
                <noscript><img class="image avatar" src="images/people/me.svg" alt="Myself"></noscript>
              </span>
              After several years working as a software developer, I pursued studies in pure
              mathematics in Madrid and Munich. My Ph.D. is on effective two dimensional theories
              for thin multi-layered materials and their minimisers, but I previously worked with
              contact problems in linear elasticity. In particular I investigated some properties of
              the coincidence set for the classical
              <a href="https://en.wikipedia.org/wiki/Signorini_problem">Signorini problem</a> and
              studied the mathematical properties of the two body problem together with some
              numerical computations, using the open source toolbox
              <a href="http://www.dune-project.org/">DUNE</a>.
              <br/>
              <br/>
              Since then I've moved into <a class="-link" href="#ml">machine learning</a> and I am
              currently (2020) working as an "applied researcher" at the <a href="https://appliedai.de">appliedAI
              initiative</a>, part of <a href="https://www.unternehmertum.de">UnternehmerTUM GmbH</a>,
              where I strive to bridge the gap between research and application.
              <br/>
              <br/>
              If you are interested in any of the stuff above or have any ideas for a talk or
              project, <a class="-link" href="#contact">drop me a line</a>.</p>
            
            <h4>This site</h4>

            <p>This site is statically hosted by <a href="https://www.netlify.com/">netlify</a>,
              with sources at <a href="https://bitbucket.org/mdbenito/web">Bitbucket</a>.
              Aside from all the javascript and css there isn't much beyond a small Makefile
              for the deployment (minimization and consolidation of assets) of the single
              html file. There are also some PDFs which I copied from my private git repositories.
              Please check the README file for the credits, licenses and dependencies.</p>
            <ul class="icons">
              <li><a class="icon-bitbucket" href="https://bitbucket.org/mdbenito/web"
                     title="Code" rel="tipsy"></a></li>
            </ul>

            <h4 id="contact">Contact</h4>

            <form method="post" action="https://formspree.io/m.debenito.d@gmail.com">
              <input type="text" name="_gotcha" style="display:none" title="Gotcha" />
              <div class="row uniform">
                <div class="6u 12u(xsmall)">
                  <input type="text" name="name" id="name" placeholder="Name">
                </div>
                <div class="6u 12u(xsmall)">
                  <input type="email" name="email" id="email" placeholder="Your email">
                </div>
              </div>
              <div class="row uniform">
                <div class="12u">
                  <input type="text" name="subject" id="subject" placeholder="Subject">
                </div>
              </div>
              <div class="row uniform">
                <div class="12u">
                  <textarea name="message" id="message" placeholder="Message" rows="6"></textarea>
                </div>
              </div>
              <div class="row uniform">
                <div class="12u">
                  <ul class="actions">
                    <li><input type="submit" class="special" value="Send Message"></li>
                    <li><input type="reset" value="Reset Form"></li>
                  </ul>
                </div>
              </div>
            </form>
          </div>
        </section>
      </div>
      <!-- Footer -->
      <section id="footer">
        <div class="container">
          <ul class="copyright">
            <li>&copy; 2016 Miguel de Benito Delgado</li>
            <li>Design based on <a href="http://html5up.net">HTML5 UP Read only</a></li>
            <li>Licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY</a></li>
          </ul>
        </div>
      </section>
    </div>
    <script src="assets/js/everything.min.js"></script>
    <!--[if lte IE 8]>
        <script src="assets/js/ie/respond.min.js"></script>
        <![endif]-->
    <!--Remove postprocessing for .disabled class once it isn't needed. -->
    <script>
      /* my stuff */function fade_others(e){var o=$($("#people").data("people"));$(o).each(function(o,a){-1==$(e).index($(a))&&$(a).fadeTo(800,.1).delay(4e3).fadeTo(600,1)})}$(".people-link").click(function(){var e=$(this).data("people");fade_others($(e))}),$(function(){$("a[rel=tipsy],li[rel=tipsy]").tipsy({fade:!0,gravity:$.fn.tipsy.autoNS,delayIn:500})});$('html').on('click','a.disabled',function(e){e.preventDefault();});$(".disabled").attr('tabindex',-1);
    </script>
  </body>
</html>
